{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow_LowerLevel_API_Basic\n",
    "xiangjl\n",
    "xjliww@163.com\n",
    "2018/10/14 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文章参考：https://tensorflow.google.cn/programmers_guide/low_level_intro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 简介\n",
    "\n",
    "本指南旨在指导您使用低级别 TensorFlow API (TensorFlow Core) 开始编程。您可以学习执行以下操作：\n",
    "\n",
    "    管理您自己的 TensorFlow 程序 (tf.Graph) 和 TensorFlow 运行时 (tf.Session)，而不是依靠 Estimator 来管理它们。\n",
    "    使用 tf.Session 运行 TensorFlow 操作。\n",
    "    在此低级别环境中使用高级别组件（数据集、层和 feature_columns）。\n",
    "    构建自己的训练循环，而不是使用 Estimator 提供的训练循环。\n",
    "\n",
    "我们建议尽可能使用更高阶的 API 构建模型。以下是 TensorFlow Core 为何很重要的原因：\n",
    "\n",
    "    如果您能够直接使用低阶 TensorFlow 操作，实验和调试都会更直接。\n",
    "    在使用更高阶的 API 时，能够理解其内部工作原理。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 设置\n",
    "\n",
    "在使用本指南之前，请先安装 TensorFlow。\n",
    "\n",
    "要充分理解本指南中的内容，您应当具备以下方面的知识：\n",
    "\n",
    "    如何使用 Python 编程。\n",
    "    对阵列有所了解。\n",
    "    理想情况下，最好对机器学习有一定的了解。\n",
    "\n",
    "您随时可以启动 python，并按照以下演示进行操作。运行以下行来设置您的 Python 环境："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 张量值\n",
    "\n",
    "TensorFlow 中的核心数据单位是张量。一个张量由一组形成阵列（任意维数）的原始值组成。张量的阶是它的维数，而它的形状是一个整数元组，指定了阵列每个维度的长度。以下是张量值的一些示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[1.0, 2.0, 3.0]], [[7.0, 8.0, 9.0]]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3.  #a rank 0 tensor; a scalar with shape [],\n",
    "\n",
    "[1., 2., 3.] # a rank 1 tensor; a vector with shape [3]\n",
    "\n",
    "[[1., 2., 3.], [4., 5., 6.]]  # a rank 2 tensor; a matrix with shape [2, 3]\n",
    "\n",
    "[[[1., 2., 3.]], [[7., 8., 9.]]] # a rank 3 tensor with shape [2, 1, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow 使用 numpy 阵列来表示张量值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 TensorFlow Core 演示\n",
    "您可以将 TensorFlow Core 程序看作由两个互相独立的部分组成：\n",
    "\n",
    "    构建计算图 (tf.Graph)。\n",
    "    运行计算图（使用 tf.Session）。\n",
    "    \n",
    "### 4.1 图(Graph)\n",
    "\n",
    "计算图是排列成一个图的一系列 TensorFlow 指令。图由两种类型的对象组成。\n",
    "\n",
    "操作（简称“op”）：图的节点。操作描述了消耗和生成张量的计算。\n",
    "    张量：图的边。它们代表将流经图的值。大多数 TensorFlow 函数会返回 tf.Tensors。\n",
    "\n",
    "***重要提示：tf.Tensors 不具有值，它们只是计算图中元素的手柄。\n",
    "\n",
    "我们来构建一个简单的计算图。最基本的指令是一个常量。构建指令的 Python 函数将一个张量值作为输入值。生成的指令不需要输入值。它在运行时输出的是被传递给构造函数的值。我们可以创建如下所示的两个浮点数常量 a 和 b：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0) # also tf.float32 implicitly\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "打印语句会生成：\n",
    "\n",
    "Tensor(\"Const:0\", shape=(), dtype=float32)\n",
    "Tensor(\"Const_1:0\", shape=(), dtype=float32)\n",
    "Tensor(\"add:0\", shape=(), dtype=float32)\n",
    "\n",
    "请注意，打印张量并不会如您可能预期的那样输出值 3.0、4.0 和 7.0。上述语句只会构建计算图。这些 tf.Tensor 对象仅代表将要运行的操作的结果。\n",
    "\n",
    "图中的每个指令都拥有唯一的名称。这个名称不同于使用 Python 分配给相应对象的名称。张量是根据生成它们的指令命名的，后面跟着输出索引，如上文的 \"add:0\" 所示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 TensorBoard\n",
    "\n",
    "TensorFlow 提供了一个名为 TensorBoard 的实用程序。TensorBoard 的诸多功能之一是将计算图可视化。您只需要使用几个简单的命令就能轻松完成此操作。\n",
    "\n",
    "首先将计算图保存为 TensorBoard 摘要文件，具体操作如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这将在当前目录中生成一个 event 文件，其名称格式如下："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "events.out.tfevents.{timestamp}.{hostname}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，在新的终端中使用以下 shell 命令启动 TensorBoard："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tensorboard --logdir ."
   ]
  },
  {
   "attachments": {
    "%E5%9B%BE%E7%89%87.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOEAAABPCAIAAACSxzWzAAAMWklEQVR4nO2dP2jqWhjAz+bo6Ojo6OjockCcMpUODuKUpSB0SadOBeEumYrDHTrKu4/7cv8RbyuvesEgzZAU7KvaS5Ar9xIoKUGshGbJG46mx/zTaqpiz2961Jim+rvf+c53vnMesAiE7QZs+gEIhDkQRwnbDnGUsO0QRwnbDnGUsO0QR3cP9WMBQghzlV+Lv+dXJQchpE6un4KuGl3SEEJ42Byt+owvgTi6c/x6n4MQQgj3Tn8GGjfzJuIoYV083bJ7cAL17nZRSYmjhHXxdH1CQQgPv349zEKYPRYXtIk4SlgTI/EoC2H2qDkaiceT//K6ThXfH9N7WQghzOYOTj5e33o5Orr+eHIwuWqPPq6IP78TRwmr8XB5CKfRcxJRD74/OK9Svx9Rk2QgR9OFiYTQ4ehD82SSNGRzBbqQe76KOEpYmoevNCba0+07CkJIf1VnL/p+CCGE2YPK7dS0B5EtwFlHR+IxBSGEBVacOj66rRwQRwkroVYKEMI9djpRevrJ7rlqUJPClMPcp5+ne7ijD5cHEEKYez9bGZi8mThKWI6f73POgtMv149GzUMIISw4gqtjzvR0fZL1Kl6RORNhBSY1p9z7mcL9r0phtgaFImH2SHTM32cdHTUPIITw4NLhInGUsDyTGZIPzzWoiaPHzhqTt6NOF4mjhKUZNY+yEMJsjj5wQBeyEMLsVKvJWO+KkK6xnoIQFj46MgLiKGFZUM3Jq85kWQ/fD/DX7MF+VjNHDd/nhg+kPkpYDvUrjYKjh6K2b9Og+HB5mIUQ5tjrZ9HUS1RpwmtPJxSEkDppPt9zJL7LkdoTYRnQxAgeeitqWaMmsnI6nZrW8LP00bvTU/bkMDfNW71q+NnC0Tv2lD05LGSnlxFHCS/j52kOzzg9QCukeCnpQXx/TKNJVpYqHJ1e3n4/gEFroZAqHLJfr5vHWeLotqCqaq/XE0WxVqs1Gg1ZlhVFGY/Hm36utwhx1Ml4PBYE4YsPvV5v0w/45iCOzqAoCs/zfoIiGo3GcDjc9JO+IXbGUbXOMky5rmM/0uWzYiYZAwAAAKKJdL7c0n3fb1mWqqpuI2u1mucPTdN85b+IMGFXHDXkYhyAONOxf9AqJgAA0XSeYctltkSnYwCARLFleN/ANE08gvI8PxgMbBHH43G73cY1bbfb6/i7CLvrqM5lIgAky/3nSzqlBADR/bq3pKIo4qO5Z5jUNA3XVNO00P8OgpvQHdXrbD4djwAAQCSW3C9VZ5bTjE6FoZKxCBp9M8Uz2TZGPUsBEM1XW2f05P3RJFWaHbzrbD6FXgOxJMVwfcOyLJ1LgxnSnG5Zhtrvqzruo3qWAiBCVb0dxSNowPy92+3aV0qStNxnRHgR4TqqV/NxAEAsTZdYtkRn4gCA2D430dRoMUkAQCS5z7Asy+wnIwCAJDMZfdWzFAAgEolEU/vFUqlEZ2IAgCjF6dN3FxMAgHim+HzvKFVRLUttVascm4kCEKPKXLXawv9ZGLqqqv1Oq8KkowAkS7KXoniAnDuI21cKgrDyJ0aYT5iOovE2ul+1Y59ez8cASKARuFNKABBJY8Nvv5yOAJBgOoY1dRRZh0BvoNDtjFY+CkCiZCecaiUNAEiWVex3Y/no9JGY+DS8RlIlv2RUURTbPFVVvS+aglem/vz5s8gnQ1iFEB2daFKciVR9rsSUKn3LsjpMHIBofiYdNFp0bGoWGooz2FBsVKkIAKkzFd2diQMQSbP43NywL/Zx1DL6rWq1yp2V8qkoANHMWd/r0fERfG6WKUmSffGHDx84jpNlWdcDSwabZjgcapqmaVovEHTNti1VhOloNfOslNerwP2qXrHF9HC0TkUASE7fordK6egkz83kmXK1g+nu5yh2xUxYnmUwGNjaDQaD4L8Tj6MfML59+7Ylsg6HQ0VRZFkWBGFuudcPnucFQUALbJutB4fpaJ2KAJCq+DrqYbBaSQEAFnPUsizLUGWuzNAUmjlFUsx0TjXfUcvoMO44j1g8HzVN077y33//bTabH1xcXFzc3d09Pj4G3Cd0hsPhzc1NwArZ6giCsJEF4VDHeg8HjH6r1ero1mSsj+VbHmN9UZ7vqKH2O53+c4wyOmw68pygOhw1OqVkNJpkZI9Q6zlrsvAvIyBs4FVSZLNpmv1+v16v+8m6SLVflmWO45aIwUhNz4WG16PRaKxT1vDnTDFszmTITMLWtsMkAIiksYywf5aJ2C8HOzq5d76uO37b5J+EMxnWq1QEgDhWskfP4lsfxeVrNBqeXwA+tfriUvnx8fHu7u78/Nwta7PZ7Pf7AbJ++/YNpbaLa6pp2iJRs1arCYIgSVK32+12u1og6BpJkgRBWMR7WZbXYOqr1J7iGbpULrNFKuFVe4qm8gxbLqNZDEgUJ9rNG+uR0JHkPsOWy+XpupEdFdE0P5qmSywquqI4CxJUkS2XJ5WuiM+cybIs0zTxb4XneTsPM03TLUS32/X7FB4fH29ubpB2blk9SwF46J0bd4PtrNVqkiSFlURqmqYoiiRJAcqKoviqyxmvWsOPp/JsfSYB1eWzYiYxmfkkMsUz2Q4b8/NRo88x+9Mavmv93eiUqUQEABCbllSNDmcvGESea/6+OJaRAmg0Ggt9Frouy7JbVo7jRFG0Zb26unJkCAGa9no9v0d67fF3PB4ritJoNDwf4PU6wnZlLTQkVFWdOxEWRfGlDSX39/dXV1ccx7lllWX5n3/+cSey7l9hmqY7fPI83+121zyPGY/H3W7X/UEt8cksAnHUiWma+Nq9QwhFUVa5+e/fvz1l9Zxv4d+3aZqOAFar1fCul/Vjmqa7lXHBEeZFEEe9GQ6Hg8Gg3W4LgiCKYrfbVVU1rHCFSgGobvXXX38toqm762pLmgPd/6RD7wgjjm4S0zSDo+n5+blpmo7G1rmrDOsHXwT5EnZHGHF0Y9zf39/f3wfEUTtn/fHjh/31B9QTNou7chwWxNFNYosYbOqnT5/sr3/Tj+wLvgIXbkcYcXSTBEdQm1f67kMHn9WFeFvi6CaZO9A74ijP85t+5CBeaXZPHN0Y/X7/7u5urqB///33xcXFNk+YEPhCMclHd4pgQXmeN03TMWvewp3TjiW6uX3iL4I46gtaqpZludfrqaoarhl+y6Q4eIuJY4VpxaWEcHEsz4qiGO79iaMe4G35OLVabcXK3+Pj43///RespltQy7W1Gs2fNr4xVdM09+pX6IsLxNEZhsOhX8+Ezc3NzUu/BtS2d3Fx4XbRs0vas0nP89kEQdhIhjoYDNydUH49jSuyM456nFOCoVf3o8CnCd9mOBwG24mbscgzBbQ/n5+f2+3Pjr6ngC5Sv14CnudlWQ43C/REVVVZlj3bbiRJeqXl2V1xNHCviF7NoxN1gh11RClJktAaPUpMHa8GZIT4crynmu5tJIsIauMZw2xZRVFEu+dCMQb1zvZ6vYCtUbVa7VX/ebwBR/U6HQMgGgt2FM9BeZ73TPXwHaGeR0X8+fNHFEV3W9Pc7XjoLS/qww8w1abRaAiCcHNz0+v1BoOB3W/vmP/Zu0Y1TRsMBr1eD22Nmnt/1Hu14AMvzc6eU2L/xhYdByBVqtB+G+4Q+EcfMBfBh1q7Cnh/f++p5uLbmlHD3hL7mVRVlSRp6c2fy8HzPBpkXvq0y7Hj55QYrWIcgGSpo3tt/rfBM9HgE3LwVekfP374tdlfXV39/v37ZZ/dapue1yDrmtW02elzStA2uwQjG94HVNi8aH+9nZh+/vzZPUl/qZqhMx6P7c7X1b0UBKHdbofYO7sEO3xOiSGXkvZpjsGOrnJOyYcFtn1uFpRoKorSnYIMtmm32/ZLiqK4E9bNsrPnlBidUhKAOD3JJIIdXfq8p/Wf9fAG2dVzSjpsCoAoVemoiH6djgEQo+t9VXXnffhy89wmYjvne429OwQ3u3lOCUpe/ZiZ91uWNTsTQm0cfn8kHnHJ+aPrYUfPKdE79eoMXJmKAhClyly1LntFenwE9+uKGA6H+MR5/TPct8nunlMyS3A+alnWeDzG/XP/z0Mc+3RD7+4h+LHL55TgzHXUch3n9GV6vqHnyQtbO4vfPXZlLTQkHNvYPfFbKSW8EsRRJ5qmBZ+/RSLomiGOeoBOiRFF0V5SspdbNv1obxHiKGHbIY4Sth3iKGHbIY4Sth3iKGHbIY4Sth3iKGHbIY4Sth3iKGHbIY4Sth3iKGHbIY4Stp3/AZFRNGPTTniiAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，在您的浏览器中打开 TensorBoard 的图页面，您应该会看到与以下图形类似的图：\n",
    "![%E5%9B%BE%E7%89%87.png](attachment:%E5%9B%BE%E7%89%87.png)\n",
    "要详细了解 TensorBoard 的计算图可视化工具，请参阅 TensorBoard：图的直观展示。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 会话 (Session)\n",
    "\n",
    "要评估张量，您需要实例化一个 tf.Session 对象（非正式名称为会话）。会话会封装 TensorFlow 运行时的状态，并运行 TensorFlow 操作。如果说 tf.Graph 像一个 .py 文件，那么 tf.Session 就像一个 python 可执行对象。\n",
    "\n",
    "下面的代码会创建一个 tf.Session 对象，然后调用其 run 方法来评估我们在上文中创建的 total 张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以将多个张量传递给 tf.Session.run。run 方法以透明方式处理元组或字典的任何组合，如下例所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ab': (3.0, 4.0), 'total': 7.0}\n"
     ]
    }
   ],
   "source": [
    "print(sess.run({'ab':(a, b), 'total':total}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "它返回的结果拥有相同的布局结构：\n",
    "\n",
    "{'ab': (3.0, 4.0), 'total': 7.0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在调用 tf.Session.run 期间，任何 tf.Tensor 都只有单个值。例如，以下代码调用 tf.random_uniform 来生成一个 tf.Tensor，后者会生成随机的三元素矢量（值位于 [0,1) 区间内）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95510316 0.4241376  0.83991647]\n",
      "[0.19749606 0.06921947 0.9127184 ]\n",
      "(array([0.50425017, 0.3607762 , 0.7452526 ], dtype=float32), array([1.5042502, 1.3607762, 1.7452526], dtype=float32), array([2.50425  , 2.3607762, 2.7452526], dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "vec = tf.random_uniform(shape=(3,))\n",
    "out1 = vec + 1\n",
    "out2 = vec + 2\n",
    "print(sess.run(vec))\n",
    "print(sess.run(vec))\n",
    "print(sess.run((vec, out1, out2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "部分 TensorFlow 函数会返回 tf.Operations，而不是 tf.Tensors。对指令调用 run 的结果是 None。您运行指令是为了产生副作用，而不是为了检索一个值。这方面的例子包括稍后将演示的初始化和训练操作。\n",
    "每次调用 run 时，结果都会显示不同的随机值，但在单个 run 期间（out1 和 out2 接收到相同的随机输入值），结果显示的值是一致的：\n",
    "\n",
    "[ 0.52917576  0.64076328  0.68353939]\n",
    "\n",
    "[ 0.66192627  0.89126778  0.06254101]\n",
    "\n",
    "(\n",
    "   \n",
    "   array([0.355803  , 0.13531041, 0.36421525], dtype=float32), \n",
    "   \n",
    "   array([1.355803 , 1.1353104, 1.3642153], dtype=float32),\n",
    "   \n",
    "   array([2.355803 ,  2.1353104, 2.3642154], dtype=float32)\n",
    "   \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 供给(Feed)\n",
    "\n",
    "目前来讲，这个图不是特别有趣，因为它总是生成一个常量结果。图可以参数化以便接受外部输入，也称为占位符。占位符表示承诺在稍后提供值，它就像函数参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32)\n",
    "y = tf.placeholder(tf.float32)\n",
    "z = x + y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "前面三行有点像函数。我们定义了这个函数的两个输入参数（x 和 y），然后对它们运行指令。我们可以使用 run 方法的 feed_dict 参数为占位符提供具体的值，从而评估这个具有多个输入的图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[3. 7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(z, feed_dict={x: 3, y: 4.5}))\n",
    "print(sess.run(z, feed_dict={x: [1, 3], y: [2, 4]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述操作的结果是输出以下内容：\n",
    "\n",
    "7.5\n",
    "[ 3.  7.]\n",
    "\n",
    "另请注意，feed_dict 参数可用于覆盖图中的任何张量。占位符和其他 tf.Tensors 的唯一不同之处在于如果没有为它们提供值，那么占位符会抛出错误。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 数据集(Dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "占位符适用于简单的实验，但数据集是将数据流式传输到模型的首选方法。\n",
    "\n",
    "要从数据集中获取可运行的 tf.Tensor，您必须先将其转换成 tf.data.Iterator，然后调用迭代器的 get_next 方法。\n",
    "\n",
    "创建迭代器的最简单的方式是采用 make_one_shot_iterator 方法。例如，在下面的代码中，next_item 张量将在每次 run 调用时从 my_data 阵列返回一行："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_data = [\n",
    "    [0, 1,],\n",
    "    [2, 3,],\n",
    "    [4, 5,],\n",
    "    [6, 7,],\n",
    "]\n",
    "slices = tf.data.Dataset.from_tensor_slices(my_data)\n",
    "itor = slices.make_one_shot_iterator()\n",
    "next_item = itor.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(next_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "到达数据流末端时，Dataset 会抛出 OutOfRangeError。例如，下面的代码会一直读取 next_item，直到没有数据可读：\n",
    "\n",
    "while True:\n",
    "  try:\n",
    "    print(sess.run(next_item))\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    break\n",
    "\n",
    "如果 Dataset 依赖于有状态操作，则可能需要在使用迭代器之前先初始化它，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.41176027  1.0784054  -0.3680334 ]\n",
      "[ 0.8959008  1.0963172 -0.4632479]\n",
      "[-0.28124255  1.0320628  -0.7933211 ]\n",
      "[-0.6821138  0.6746572  1.1010113]\n",
      "[-1.5017749 -0.6715717  0.9798447]\n",
      "[ 0.32035723  0.44352624 -1.6000073 ]\n",
      "[-0.3110048 -0.6508491  1.4643897]\n",
      "[-1.86328    0.939101  -0.3264654]\n",
      "[-0.68554914 -0.84203994 -0.08805015]\n",
      "[-0.61839926  1.280179    0.85706055]\n"
     ]
    }
   ],
   "source": [
    "r = tf.random_normal([10,3])\n",
    "dataset = tf.data.Dataset.from_tensor_slices(r)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "next_row = iterator.get_next()\n",
    "\n",
    "sess.run(iterator.initializer)\n",
    "while True:\n",
    "  try:\n",
    "    print(sess.run(next_row))\n",
    "  except tf.errors.OutOfRangeError:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要详细了解数据集和迭代器，请参阅导入数据。https://tensorflow.google.cn/programmers_guide/datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 层(Layer)\n",
    "\n",
    "可训练的模型必须修改图中的值，以便在输入相同值的情况下获得新的输出值。将可训练参数添加到图中的首选方法是层。\n",
    "\n",
    "层将变量和作用于它们的操作打包在一起。例如，密集连接层会对每个输出对应的所有输入执行加权和，并应用激活函数（可选）。连接权重和偏差由层对象管理。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 创建层\n",
    "\n",
    "下面的代码会创建一个 Dense 层，该层会接受一批输入矢量，并为每个矢量生成单一的输出值。要将层应用于输入值，请将该层当做函数来调用。例如"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "y = linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "层会检查其输入数据，以确定其内部变量的大小。因此，我们必须在这里设置 x 占位符的形状，以便层构建正确大小的权重矩阵。\n",
    "\n",
    "我们现在已经定义了输出值 y 的计算，在我们运行计算之前，还需要处理一个细节。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 初始化层\n",
    "\n",
    "层包含的变量必须先初始化，然后才能使用。尽管可以单独初始化各个变量，但您也可以轻松地初始化一个 TensorFlow 图中的所有变量（如下所示）："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***重要提示：调用 tf.global_variables_initializer 仅会创建并返回 TensorFlow 操作的句柄。当我们使用 tf.Session.run 运行该操作时，该操作将初始化所有全局变量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "另请注意，此 global_variables_initializer 仅会初始化创建初始化程序时图中就存在的变量。因此您应该在构建图表的最后一步添加初始化程序。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 执行层\n",
    "\n",
    "我们现在已经完成了层的初始化，可以像处理任何其他张量一样评估 linear_model 的输出张量了。例如，下面的代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.8909655]\n",
      " [-10.583069 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(y, {x: [[1, 2, 3],[4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "会生成一个两元素输出向量，如下所示：\n",
    "\n",
    "[[-3.41378999]\n",
    "\n",
    " [-9.14999008]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 层函数的快捷方式\n",
    "对于每个层类（如 tf.layers.Dense)，TensorFlow 还提供了一个快捷函数（如 tf.layers.dense）。两者唯一的区别是快捷函数版本是在单次调用中创建和运行层。例如，以下代码等同于较早的版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9098539]\n",
      " [5.0244675]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, 3])\n",
    "y = tf.layers.dense(x, units=1)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y, {x: [[1, 2, 3], [4, 5, 6]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管这种方法很方便，但无法访问 tf.layers.Layer 对象。这会让自省和调试变得更加困难，并且无法重复使用相应的层。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 特征列\n",
    "\n",
    "使用特征列进行实验的最简单方法是使用 tf.feature_column.input_layer 函数。此函数只接受密集列作为输入，因此要查看类别列的结果，您必须将其封装在 tf.feature_column.indicator_column 中。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = {\n",
    "    'sales' : [[5], [10], [8], [9]],\n",
    "    'department': ['sports', 'sports', 'gardening', 'gardening']}\n",
    "\n",
    "department_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        'department', ['sports', 'gardening'])\n",
    "department_column = tf.feature_column.indicator_column(department_column)\n",
    "\n",
    "columns = [\n",
    "    tf.feature_column.numeric_column('sales'),\n",
    "    department_column\n",
    "]\n",
    "\n",
    "inputs = tf.feature_column.input_layer(features, columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行 inputs 张量会将 features 解析为一批向量。\n",
    "\n",
    "特征列和层一样具有内部状态，因此通常需要将它们初始化。类别列会在内部使用对照表，而这些表需要单独的初始化操作 tf.tables_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_init = tf.global_variables_initializer()\n",
    "table_init = tf.tables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run((var_init, table_init))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化内部状态后，您可以像运行任何其他 tf.Tensor 一样运行 inputs："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  5.]\n",
      " [ 1.  0. 10.]\n",
      " [ 0.  1.  8.]\n",
      " [ 0.  1.  9.]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(inputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这显示了特征列如何打包输入矢量，并将独热“department”作为第一和第二个索引，将“sales”作为第三个索引。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 训练\n",
    "您现在已经了解 TensorFlow 核心部分的基础知识了，我们来手动训练一个小型回归模型吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 定义数据\n",
    "\n",
    "我们首先来定义一些输入值 x，以及每个输入值的预期输出值 y_true："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 定义模型\n",
    "\n",
    "接下来，建立一个简单的线性模型，其输出值只有 1 个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = tf.layers.Dense(units=1)\n",
    "\n",
    "y_pred = linear_model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "您可以如下评估预测值："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.42472517]\n",
      " [0.84945035]\n",
      " [1.2741755 ]\n",
      " [1.6989007 ]]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "print(sess.run(y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该模型尚未接受训练，因此四个“预测”值并不理想。以下是我们得到的结果，您自己的输出应该有所不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 损失\n",
    "要优化模型，您首先需要定义损失。我们将使用均方误差，这是回归问题的标准损失。\n",
    "\n",
    "虽然您可以使用较低级别的数学运算手动定义，但 tf.losses 模块提供了一系列常用的损失函数。您可以使用它来计算均方误差，具体操作如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.100188\n"
     ]
    }
   ],
   "source": [
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "print(sess.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行，这会生成一个损失值。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 训练\n",
    "\n",
    "TensorFlow 提供了优化器来执行标准的优化算法。这些优化器被实现为 tf.train.Optimizer 的子类。它们会逐渐改变每个变量，以便将损失最小化。最简单的优化算法是梯度下降法，由 tf.train.GradientDescentOptimizer 实现。它会根据损失相对于变量的导数大小来修改各个变量。例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该代码构建了优化所需的所有图组件，并返回一个训练指令。该训练指令在运行时会更新图中的变量。您可以按以下方式运行该指令："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030190578\n",
      "0.028433332\n",
      "0.026778348\n",
      "0.025219724\n",
      "0.023751806\n",
      "0.022369325\n",
      "0.021067303\n",
      "0.019841079\n",
      "0.01868623\n",
      "0.017598601\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "  _, loss_value = sess.run((train, loss))\n",
    "  if i % 10 == 0:\n",
    "    print(loss_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 train 是一个指令而不是张量，因此它在运行时不会返回一个值。为了查看训练期间损失的进展，我们会同时运行损失张量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 完整程序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.196773\n",
      "0.2003301\n",
      "0.09159237\n",
      "0.08374959\n",
      "0.07880994\n",
      "0.07422109\n",
      "0.069901\n",
      "0.06583239\n",
      "0.0620006\n",
      "0.058391828\n",
      "[[-0.37865502]\n",
      " [-1.1834843 ]\n",
      " [-1.9883136 ]\n",
      " [-2.7931428 ]]\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([[1], [2], [3], [4]], dtype=tf.float32)\n",
    "y_true = tf.constant([[0], [-1], [-2], [-3]], dtype=tf.float32)\n",
    "\n",
    "linear_model = tf.layers.Dense(units=1)\n",
    "\n",
    "y_pred = linear_model(x)\n",
    "loss = tf.losses.mean_squared_error(labels=y_true, predictions=y_pred)\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "for i in range(100):\n",
    "  _, loss_value = sess.run((train, loss))\n",
    "  if i % 10 == 0:\n",
    "    print(loss_value)\n",
    "\n",
    "print(sess.run(y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 后续步骤\n",
    "要详细了解如何使用 TensorFlow 构建模型，请参阅以下内容：\n",
    "\n",
    "    自定义 Estimator，了解如何使用 TensorFlow 构建自定义模型。掌握 TensorFlow Core 知识有助于理解和调试您自己的模型。\n",
    "    https://tensorflow.google.cn/get_started/custom_estimators\n",
    "\n",
    "如果您想详细了解 TensorFlow 的内部工作原理，请参阅以下文档。这些文档深入探讨了这篇文章中提及的许多主题：\n",
    "\n",
    "    图和会话 https://tensorflow.google.cn/programmers_guide/graphs\n",
    "    张量 https://tensorflow.google.cn/programmers_guide/tensors\n",
    "    变量 https://tensorflow.google.cn/programmers_guide/variables\n",
    "    保存和恢复 https://tensorflow.google.cn/programmers_guide/saved_model\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
